{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_path = 'Semantic-Aware-Attention-Based-Deep-Object-Co-segmentation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, math, time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import PIL\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image\n",
    "%matplotlib inline\n",
    "import skimage, skimage.transform\n",
    "import sys\n",
    "sys.path.append(code_path)\n",
    "from torchvision import models\n",
    "import scipy.io as sio\n",
    "from scipy.io import loadmat\n",
    "import torch.nn.functional as F\n",
    "# CUDA flag. Speed-up due to CUDA is mostly noticable for large batches.\n",
    "cuda = True\n",
    "from PIL import Image,ImageDraw\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize, Scale, ToPILImage\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "#from skimage import io, transform\n",
    "from model import *\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as albu\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn as nn\n",
    "import torchvision.models.resnet as resnet_util\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "from torch.optim import Adam\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAM DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change load dir\n",
    "img_path1 = 'Data_ham/HAM10000_images_part_1/' \n",
    "img_path2 = 'Data_ham/HAM10000_images_part_2/'\n",
    "gt_path = 'Data_ham/HAM_MASK/'\n",
    "\n",
    "im_dir = np.array(sorted(os.listdir(img_path1)+os.listdir(img_path2)))\n",
    "gt_dir = np.array(sorted(os.listdir(gt_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change save path\n",
    "el_path = 'Data_ham/HAM_ellipse/'\n",
    "grab_path = 'Data_ham/HAM_grabcut/'\n",
    "os.mkdir(el_path)\n",
    "os.mkdir(grab_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ellipse(gray):\n",
    "    thresh = cv2.threshold(gray, 252, 255, cv2.THRESH_BINARY)[1]\n",
    "    points = np.column_stack(np.where(thresh.transpose() > 0))\n",
    "    hull = cv2.convexHull(points)\n",
    "    if hull.shape[0]<5:\n",
    "        return None,None,None,None,None\n",
    "    ((centx,centy), (width,height), angle) = cv2.fitEllipse(hull)\n",
    "    result = gray.copy()\n",
    "    cv2.ellipse(result, (int(centx),int(centy)), (int(width/2),int(height/2)), angle, 0, 360, (0,0,255), 2)\n",
    "    return centx,centy,width,height,angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "def save_mask(i):\n",
    "    img = image.imread(gt_path+gt_dir[i])\n",
    "    if (img==1).all() or (img==0).all():\n",
    "        wrong.append(i)\n",
    "        return\n",
    "    if len(img.shape)==3:\n",
    "        img = img[:,:,0]\n",
    "    sizes = np.shape(img) \n",
    "    fake=np.zeros(sizes,np.uint8)\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(1, 1, forward=False)\n",
    "    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "                hspace = 0, wspace = 0)\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "    ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "    centx,centy,width,height,angle = draw_ellipse(255*img.astype('uint8'))\n",
    "    if centx==None:\n",
    "        wrong.append(i)\n",
    "        return\n",
    "    ax.add_patch(Ellipse((centx,centy), height=height, \n",
    "                    width=width,\n",
    "                    angle=angle,\n",
    "                    edgecolor='white',\n",
    "                    facecolor='white',\n",
    "                    linewidth=0))\n",
    "\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    ax.imshow(fake, cmap = 'gray')\n",
    "    plt.savefig(el_path+gt_dir[i], dpi = sizes[1],bbox_inches = 'tight',pad_inches = 0) \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFkAAABZCAYAAABVC4ivAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAABJUlEQVR4nO3dsU0EMRBAURtRwhGz/deyWwQx9GDy0yaLuI+A98KRg9EPnM5caw0e6+mnF/gPRA6IHBA5IHLg+crj2+22tm170Cq/33EcH2utl/v5pcjbto19379vqz9mzvl2NvddBEQOiBwQOSByQOSAyAGRAyIHRA6IHBA5IHJA5IDIAZEDIgdEDogcEDkgckDkgMgBkQMiB0QOiBwQOSByQOSAyAGRAyIHRA6IHBA5IHJA5IDIAZEDIgdEDogcEDkgckDkgMgBkQMiB0QOiBwQOSByQOSAyAGRAyIHRA6IHBA5IHJA5IDIAZEDIgdEDogcEDkgckDkwLxyxWzO+T7GOD3zwBhjjNezOyOXIvM1vouAyAGRAyIHRA6IHBA5IHJA5MAn4JAaU4qa7fEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wrong=[]\n",
    "for i in range(len(gt_dir)):\n",
    "    save_mask(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1736, 3925, 5513]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Grabcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_dir = np.array(sorted(os.listdir(el_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRect(mask):\n",
    "    cand=np.where(mask==1)\n",
    "    x_min=min(cand[1])\n",
    "    x_max=max(cand[1])\n",
    "    y_min=min(cand[0])\n",
    "    y_max=max(cand[0])\n",
    "    w = x_max-x_min\n",
    "    h = y_max-y_min\n",
    "    return (x_min,y_min,w,h)\n",
    "\n",
    "def getGrabcut(img,mask):\n",
    "    img = img.astype('uint8')\n",
    "    mask = mask.astype('uint8')\n",
    "    bgdModel = np.zeros((1,65),np.float64)\n",
    "    fgdModel = np.zeros((1,65),np.float64)\n",
    "    img1 = img*mask[:,:,np.newaxis]\n",
    "    mask1 = deepcopy(mask)\n",
    "    rect = getRect(mask1)\n",
    "    cv2.grabCut(img1,mask1,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n",
    "    mask2 = np.where((mask1==2)|(mask1==0),0,1).astype('uint8')\n",
    "    if (mask2==0).all():\n",
    "        return mask\n",
    "    return mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong=[1736, 3925, 5513]\n",
    "im_dir=np.delete(im_dir,wrong)\n",
    "gt_dir=np.delete(gt_dir,wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(im_dir)):\n",
    "    if os.path.isfile(os.path.join(img_path1, im_dir[i])):\n",
    "        img=image.imread(img_path1+im_dir[i])\n",
    "    else:\n",
    "        img = image.imread(img_path2+im_dir[i])\n",
    "    mas = image.imread(el_path+el_dir[i])\n",
    "    newmask = getGrabcut(cv2.resize(img,(120,120)),cv2.resize(mas[:,:,0],(120,120)))\n",
    "    cv2.imwrite(grab_path+el_dir[i], newmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_dir = np.array(sorted(os.listdir(grab_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(grab_dir)):\n",
    "    cv2.imwrite(grab_path+grab_dir[i],(255*255*image.imread(grab_path+grab_dir[i])).astype('uint8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genarate Cluster Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to change\n",
    "num_class=45\n",
    "label_save_path='Data_ham/HAM_LABELS.npy'\n",
    "recist_save_path='Data_ham/HAM_RECIST.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "recist = []\n",
    "for i in range(len(gt_dir)):\n",
    "    if i in wrong:\n",
    "        continue\n",
    "    img = image.imread(gt_path+gt_dir[i])\n",
    "    if len(img.shape)==3:\n",
    "        img=img[:,:,0]\n",
    "    img = cv2.resize(img,(120,120))\n",
    "    recist.append(draw_ellipse(255*img.astype('uint8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10012, 5)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recist=np.stack(recist)\n",
    "recist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(recist_save_path,recist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "recist = np.load(recist_save_path)\n",
    "kmeans = KMeans(n_clusters=num_class, random_state=0).fit(recist)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10012,)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(label_save_path,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
